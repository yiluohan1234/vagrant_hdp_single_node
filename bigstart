#!/bin/bash
INSTALL_PATH=/opt/module

check_process(){
    pid=$(ps -ef 2>/dev/null | grep -v grep | grep -i $1 | awk '{print $2}')
    ppid=$(netstat -nltp 2>/dev/null | grep $2 | awk '{print $7}' | cut -d '/' -f 1)
    echo $pid
    [[ "$pid" =~ "$ppid" ]] && [ "$ppid" ] && return 0 || return 1
}

dfs(){
    usage="Usage: $0 (start|stop)"

    if [ $# -lt 1 ]; then
        echo $usage
        exit 1
    fi
    case $1 in
        start)
            $INSTALL_PATH/hadoop/sbin/start-dfs.sh
            ;;
        stop)
            $INSTALL_PATH/hadoop/sbin/stop-dfs.sh
            ;;
        format)
            $INSTALL_PATH/hadoop/bin/hdfs namenode -format
            ;;
        restart)
            dfs stop
            dfs start
            ;;
        *)
            echo $usage
            ;;
    esac
}

yarn(){
    usage="Usage: $0 (start|stop)"

    if [ $# -lt 1 ]; then
        echo $usage
        exit 1
    fi
    case $1 in
        start)
            $INSTALL_PATH/hadoop/sbin/start-yarn.sh
            ;;
        stop)
            $INSTALL_PATH/hadoop/sbin/stop-yarn.sh
            ;;
        restart)
            yarn stop
	        yarn start
            ;;
        *)
            echo $usage
            ;;
    esac
}

historyserver(){
    usage="Usage: $0 (start|stop)"

    if [ $# -lt 1 ]; then
        echo $usage
        exit 1
    fi
    case $1 in
        start)
            echo " --------------- Start historyserver ---------------"
            $INSTALL_PATH/hadoop/sbin/mr-jobhistory-daemon.sh start historyserver
            ;;
        stop)
            echo " --------------- Stop historyserver ---------------"
            $INSTALL_PATH/hadoop/sbin/mr-jobhistory-daemon.sh stop historyserver
            ;;
        restart)
            historyserver stop
	        historyserver start
            ;;
        *)
            echo $usage
            ;;
    esac
}

hadoop(){
    usage="Usage: $0 (start|stop|format)"

    if [ $# -lt 1 ]; then
        echo $usage
        exit 1
    fi
    case $1 in
        start)
            $INSTALL_PATH/hadoop/sbin/start-all.sh
            ;;
        stop)
            $INSTALL_PATH/hadoop/sbin/stop-all.sh
            ;;
        restart)
            hadoop stop
            hadoop start
            ;;
        format)
            ssh hadoop "$INSTALL_PATH/hadoop/bin/hdfs namenode -format"
            ;;
        *)
            echo $usage
            ;;
    esac
}


hbase(){
    usage="Usage(hbase): $0 (start|stop)"

    if [ $# -lt 1 ]; then
        echo $usage
        exit 1
    fi
    case $1 in
        start)
            $INSTALL_PATH/hbase/bin/start-hbase.sh
            ;;
        stop)
            $INSTALL_PATH/hbase/bin/stop-hbase.sh
            ;;
        *)
            echo $usage
            ;;
    esac
}

hive(){
    USAGE="Usage: $0 (start|stop|status)"
    HIVE_LOG_DIR=$INSTALL_PATH/hive/logs
    [ ! -d ${HIVE_LOG_DIR} ] && mkdir ${HIVE_LOG_DIR}

    case $1 in
        start)
            metapid=$(check_process HiveMetastore 9083)
            cmd="nohup hive --service metastore > $HIVE_LOG_DIR/metastore.log 2>&1 &"
            cmd=$cmd" sleep 4; hdfs dfsadmin -safemode wait >/dev/null 2>&1"
            [ -z "$metapid" ] && eval $cmd || echo "Metastroe have started"
            server2pid=$(check_process HiveServer2 10000)
            cmd="nohup hive --service hiveserver2 > $HIVE_LOG_DIR/hiveServer2.log 2>&1 &"
            [ -z "$server2pid" ] && eval $cmd || echo "HiveServer2 have started"
            ;;
        stop)
            metapid=$(check_process HiveMetastore 9083)
            [ "$metapid" ] && kill $metapid || echo "Metastore is not started"
            server2pid=$(check_process HiveServer2 10000)
            [ "$server2pid" ] && kill $server2pid || echo "HiveServer2 is not started"
            ;;
        status)
            check_process HiveMetastore 9083 >/dev/null && echo "Metastore is running normally" || echo "Metastore running abnormally"
            check_process HiveServer2 10000 >/dev/null && echo "HiveServer2 is running normally" || echo "HiveServer2 running abnormally"
            ;;
        "initSchema")
            schematool -initSchema -dbType mysql
            ;;
        "restart")
            hive stop
            sleep 2
            hive start
            ;;
        *)
            echo $USAGE
            exit 1
            ;;
    esac
}

zk(){
    usage="Usage: $0 (start|stop|status)"

    if [ $# -lt 1 ]; then
        echo $usage
        exit 1
    fi
    case $1 in
        start)
            $INSTALL_PATH/zookeeper/bin/zkServer.sh start
            ;;
        stop)
            $INSTALL_PATH/zookeeper/bin/zkServer.sh stop
            ;;
        status)
            $INSTALL_PATH/zookeeper/bin/zkServer.sh status
            ;;
        *)
            echo $usage
            ;;
    esac
}

kafka(){
    usage="Usage: $0 (start|stop)"

    if [ $# -lt 1 ]; then
        echo $usage
        exit 1
    fi
    case $1 in
        start)
            $INSTALL_PATH/kafka/bin/kafka-server-start.sh -daemon $INSTALL_PATH/kafka/config/server.properties
            ;;
        stop)
            ps -ef | awk '/Kafka/ && !/awk/{print $2}' | xargs kill -9
            ;;
        *)
            echo $usage
            ;;
    esac
}

spark(){
    usage="Usage(spark): $0 (start|stop)"

    if [ $# -lt 1 ]; then
        echo $usage
        exit 1
    fi
    case $1 in
        start)
            $INSTALL_PATH/spark/sbin/start-all.sh
            ;;
        stop)
            $INSTALL_PATH/spark/sbin/stop-all.sh
            ;;
        *)
            echo $usage
            ;;
    esac
}

flink(){
    usage="Usage(flink): $0 (start|stop)"

    if [ $# -lt 1 ]; then
        echo $usage
        exit 1
    fi
    case $1 in
        start)
            $INSTALL_PATH/flink/bin/start-cluster.sh
            ;;
        stop)
            $INSTALL_PATH/flink/bin/stop-cluster.sh
            ;;
        *)
            echo $usage
            ;;
    esac
}

args()
{
    usage="Usage: $0 (dfs|yarn|zk|kafka|spark|flink|hbase|)"

    if [ $# -lt 2 ]; then
        echo $usage
        exit 1
    fi

    case $1 in
      dfs)
        dfs $2
        ;;
      yarn)
        yarn $2
        ;;
      historyserver)
        historyserver $2
        ;;
      hdp)
        hadoop $2
        ;;
      spark)
        spark $2
        ;;
      zookeeper)
        zk $2
        ;;
      flink)
        flink $2
        ;;
      hbase)
        hbase $2
        ;;
      kafka)
        kafka $2
        ;;
      hive)
        hive $2
        ;;
      *)
        echo $usage
        ;;
    esac
}
args $@
